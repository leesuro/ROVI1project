\chapter{Feature extraction} % (fold)
\label{chap:feature_extraction}
This chapters describes different approaches on the marker detection. It explains the trade-offs,methods that have been considered and applied for the different markers. The markers that have been analysed and detected in this project are Marker 1 (Color), Marker 2 (Thin lines) and Marker 3 (Corny). 

It is a trade-off between speed (how many detections per second) and precision (how precise the detection is). It is necessary to know whether a fast or a slowly moving object is being tracked. There are several options available. As more features are added to the code, runtime is likely to become longer. The runtime also depends on the computational capability of the computer.

Another trade-off lies in the universality of the detection - whether the detection is effective in a closed artificial environment (easier to detect) or in real "chaotic" environment (the simple methods may fail).

\newpage




\section{Marker 1 (Color)} 

\begin{figure}[ht!]
	\centering
	\includegraphics[width=100px]{figures/Marker1}
	\caption{Marker 1 Color}
	\label{fig:markerColor}
\end{figure}

This section focuses on detection of marker 1 (figure \ref{fig:markerColor}) and feature extraction from the given image sequences.
Here very satisfying results have been achieved with both EASY and HARD sequences. To identify the marker a following approach has been used: color segmentation, contour finding and detecting color blobs, filtering all results, getting reference points from the marker. 

\subsection{Segmentation and contours}
For color segmentation method has been implemented. First the image has been converted into HSV color space (figure \ref{fig:c1}), which is better (than RBG) to use with the purposes of computer vision. Then on the HSV image has been applied a threshold (figure \ref{fig:c2}), first using euclidean  distance, which was quite effective for the EASY sequence, but for the HARD sequence an extended threshold range is required (luminosity changes as well as disturbing background). Therefore we used threshold with extended range.

After threshold many small points and small areas remain detected. To eliminate these disturbing features, the morphological 
opening(figure \ref{fig:c3})  is applied first (Erode-Dilate), then closing (figure \ref{fig:c4}) is applied (Dilate-Erode) to fill the small holes. 

To get the contours from the image, findContours() is used. This method records all the found contours on the previously thresholded
image.

\begin{figure}[ht!]
	\begin{subfigure}{.49\textwidth}
		\centering
		\includegraphics[width=\textwidth]{figures/color1}
	\caption{HSV}
	\label{fig:c1}
	\end{subfigure}
	\begin{subfigure}{0.49\textwidth}
		\centering
		\includegraphics[width=\textwidth]{figures/color2}
	\caption{threshold}
	\label{fig:c2}
	\end{subfigure}
		\begin{subfigure}{.49\textwidth}
		\centering
		\includegraphics[width=\textwidth]{figures/color3}
	\caption{after morphological Opening}
	\label{fig:c3}
	\end{subfigure}
	\begin{subfigure}{0.49\textwidth}
		\centering
		\includegraphics[width=\textwidth]{figures/color4}
	\caption{after morphological Closing}
	\label{fig:c4}
	\end{subfigure}
\caption{HARD sequence - Segmentation}
\label{fig:markerColorSegmenation}
\end{figure}

\subsection{Center of mass}
For calculating the center of mass of the circles several options are available.
One possible solution is to calculate the centre of mass with use of the openCV function
moments() that calculates the moment of a contours and from these moment calculate the
center of mass. This is a very effective solution for calculating the center of mass of
objects with various shapes. This method seems to work perfectly for the easy and quite good
for the HARD sequence. Problem of this method occurs when detecting the marker in the hard sequence,
there sometimes the detected circle contours are not complete (luminosity differences) and the resulting
center of mass is shifted. Of course this problem could be removed by increasing the threshold range, but
then additional contours may occur - this would require improved filtering (by distance, shape) witch would
require more computational time. 



\begin{figure}[ht!]
	\begin{subfigure}{.49\textwidth}
		\centering
		\includegraphics[width=\textwidth]{figures/Marker1centers}
	\caption{Contour view}
	\label{fig:markerColorcenter1}
	\end{subfigure}
	\begin{subfigure}{0.49\textwidth}
		\centering
		\includegraphics[width=\textwidth]{figures/Marker1centers2}
	\caption{Actual image}
	\label{fig:markerColorcenter2}
	\end{subfigure}
\caption{Center of mass (yellow - moments method, red - minEnclosingCircle)}
\label{fig:markerColorcenter}
\end{figure}

The shapes that need to be detected have circle shapes. For this reason another less time-consuming 
method has been implemented. The center of mass is calculated with function minEnclosingCircle() witch calculates
a surround circle for a given contour. This method also eliminates the marker detection problems with HARD sequence (occurring with
the moments method).When using this function the output circle center point is the center of mass of the detected circle. this method improves the performance over the previously used moment method and the HARD sequence detection then proceeds without problems. This method can be improved with using approxPolyDP() before calling the minEnclosingCircle(). This functions approximates the contour polygon and smoothens possible holes. Without approxPolyDP() the marker detection is faster. 

The difference in outputs of both methods is ranging from 1-5 pixels. When having discovered all the contours very good the first (moments) method is more accurate, but when it comes to problems with damaged contours (luminosity changes) the second method is performing better (figure \ref{fig:markerColorcenter}). 

\subsection{Filtering}

When having extracted all the contours, it is necessary to filter the desired and undesired results. To do so, the bad results are
omitted using the previously calculated contour dimensions (minimal enclosing circle). In the algorithm the position of both, the RED circle and BLUE circles is detected. It is possible both to calculate the center of marker by averaging the points and also export individual points separately. 


\subsection{Marker 1 - Conclusions}
This feature extraction program was tested with EASY and also HARD sequence. EASY sequence required much less effort (possible to track only the green marker plane). The HARD sequence required much closer analysis. A lot of disturbing features occur there (luminosity changes, background objects with color similarities, etc.). Here the filtering is more important as well as proper
thresholding. The implemented method required advanced tuning and proper parameter settings. 

In the end the marker is detected in all EASY, and also in the HARD sequence. In HARD sequence the detection is very precise when
the marker is facing straight against the camera, when the marker is turned to side (shear), the center of mass detection is around 4 pixels more precise with the moments method (however this method quite fails if the contours are not complete), but otherwise the minEnclosingCircle() method is satisfying. 

The average runtime for HARD is 24.6782 ms, for EASY 17.0602 ms with the complex and precise algorithm. Around 50 ms with the simple algorithm (less precise, one color threshold only - RED, BLUE, or GREEN plate).


\newpage
\section{Marker 2 (2a Thin lines)}

\begin{figure}[ht!]
	\centering
	\includegraphics[width=100px]{figures/Marker2a}
	\caption{Marker 2 Thin lines}
	\label{fig:markerLines}
\end{figure}

For the second, Marker 2a a following approach was selected: Canny edge detection, then applying Hough line transform,
line assuming and finding intersections, filtering proper intersections and finally detecting the marker. The implemented 
program was able to detect the marker 2a in 100 \% EASY sequence pictures and in 50 \% of the HARD sequence markers. This 
detecting method however was the fastest one (among Marker 1 and 3).

\subsection{Line detecting}
To detect the lines openCV hough lines transform has been applied. The perform the method, first edge detection is necessary.
Canny and Sobel edge detections have been considered. Canny detection has been selected (figure \ref{fig:linesCanny}), because it can detect edges very good with the smooth continuous pixels (Sobel doesn't produce so continuous pixels). Canny edge detection parameters depend on given environment. 

\begin{figure}[ht!]
	\begin{subfigure}{.49\textwidth}
		\centering
		\includegraphics[width=\textwidth]{figures/lines1}
	\caption{Original image}
	\label{fig:l1}
	\end{subfigure}
	\begin{subfigure}{0.49\textwidth}
		\centering
		\includegraphics[width=\textwidth]{figures/lines2}
	\caption{Canny edge}
	\label{fig:l2}
	\end{subfigure}
\caption{Canny edge detection}
\label{fig:linesCanny}
\end{figure}

After the detection has been performed, the Hough line transform has been applied (figure \ref{fig:linesHough}). When setting the parameters better result have been achieved when setting higher vote count (around 200), the line thickness has been set 2 pix, angle 1Â°. Otherwise too many undesired lines are found.

\begin{figure}[ht!]
	\centering
	\includegraphics[width=\textwidth]{figures/lines3}
	\caption{Detected and filtered lines }
	\label{fig:linesHough}
\end{figure}

\subsection{Finding and filtering line crossings}
After finding the lines the crossing detections is initiated (figure \ref{fig:l4}). From the vector of found lines are selected all possible line pairs. First, for each pair a calculations is performed (with function isPossible()) whether the lines have a chance to cross each other.

If the lines cross, a function calculateLineCrossing() is called which calculates the point of intersection. 

\begin{figure}[ht!]
	\begin{subfigure}{.49\textwidth}
		\centering
		\includegraphics[width=\textwidth]{figures/lines4}
	\caption{Detected crossings}
	\label{fig:l4}
	\end{subfigure}
		\begin{subfigure}{.49\textwidth}
		\centering
		\includegraphics[width=\textwidth]{figures/lines5}
	\caption{Detected crossings 2}
	\label{fig:l5}
	\end{subfigure}
	\begin{subfigure}{\textwidth}
		\centering
\includegraphics[width=0.5\textwidth]{figures/lines6}
	\caption{Filtered crossings}
	\label{fig:l6}
	\end{subfigure}
\caption{Canny edge detection}
\label{fig:linesCrossings}
\end{figure}

\subsection{Filtering and marker position establishing}
First filtering is performed right after the Hough line transform had been called. There only orthogonal lines are selected (all other astray lines are filtered out). This assures that we get closer to the marker - all the lines that are not parallel or orthogonal to the marker lines are erased.

Then the calculated crossings require filtering. The lines crossing the marker have higher density (more lines crosses one single marker line) therefore more line crossings appear on the marker line crossings. This has been used to filter the crossings - places with higher crossing density
remain, while less density crossings are omitted (figure \ref{fig:l6}). 

Finally from the remaining crossings the center of gravity
is calculated. 

\subsection{Marker 2 - Conclusions}
The methods implemented detect the marker in EASY sequence 
every time, in HARD sequence 50 \% in average time 15 ms, but they detect the center of marker imprecisely (localization of the marker moves around 100-150 pixels in the border of the marker).
Therefore additional crossings filtering is required (filter by mutual crossings distance and angles).

\newpage
\section{Marker 3 (Corny)}

\begin{figure}[ht!]
	\centering
	\includegraphics[width=100px]{figures/Marker3}
	\caption{Marker 3 Corny}
	\label{fig:markerCorny}
\end{figure}

For the third marker, the previous approaches would not achieve big success detecting the corny image. Colour segmentation would be fast, but only partially effective and imprecise. The lines extraction method would not be able to extract lines from the edgy image. On the other hand, the rich marker structure is very appropriate for the SIFT (Scale-invariant feature transform) feature detection. Although this detection method brings good results it is quite slow, therefore a faster SURF (Speeded Up Robust Features) feature detection method has been applied. 

\subsection{Feature extraction and marker recognition}

When detecting the marker in the given environment, first thing that is done is extracting features from the clear marker image, so later these features can be compared and searched for in the scene with marker put in the environment. The images are loaded in gray scale. Then a SURF detector is created to find the matches between the marker image and the scene. 

For the SURF detector, various parameters were set to calibrate it properly, for instance with the hessian threshold, smaller values (100-400) cause detecting a lot of matches, bigger (500-1000) produce less matches, but then errors may occur. 

Key points are extracted from both object and also scene. After getting the key points, the descriptors are being calculated for both marker image and scene image with the compute() method of descriptor extactor (SurfDescriptorExtractor). 

To find the matches in features between both images, fast FLANN matcher is applied. Other methods like brute force give good results, even in difficult image contexts, where FLANN is weaker, but the focus was to get fast results. The bad matches are then filtered out.

\begin{figure}[ht!]
	\centering
	\includegraphics[width=\textwidth]{figures/corny1}
	\caption{Corny marker detection}
	\label{fig:corny1}
\end{figure}
\newpage
Finally to localize the object, findHomography() method is applied. This method finds homography between two images from given sets of points. These points are the good matches in both marker and scene images. When calculating homography RANSAC (Random Sample Consensus) robust method is used. To detect perspective changes, perspectiveTransform() method is applied to calculate the marker corners. These corners then serve to calculate the center of marker. 



\subsection{Marker 3 - Conclusions}
Detecting markers containing a lot of features with SURF method is very effective and precise, 100\% markers have been detected in the EASY and also in the HARD sequence. 

The negative property of this method compared to the previous methods is the detection speed. It is very slow, as the feature finding, calculating and matching takes too long time (average 380.667 ms).
% chapter featre_extraction (end)

\section{Feature extraction Conclusions}
It has been discovered that multiple detecting methods can be applied and combined to achieve different results. There are trade-offs that have to be done - whether to detect precisely or fast, or when dealing with different environments. 

The color blob method is very fast, but sensitive to environment changes. It is also a quite low-resource consuming method.

The line extraction method works good when having a proper environment, but the line allignment on marker assures good detection. 

The SURF method among all is very precise in a variety of different kinds of environments, but is very slow. 